---
layout: post
comments: true
title:  "Simple LSTM"
excerpt: "A nice post"
date:   2014-07-02 10:00:00
mathjax: true
---
A few weeks ago I released some [code](https://github.com/nicodjimenez/lstm) on github to help people understand how LSTM's work at the implementation level.  I've since received several requests for more information about where the backprop equations come from.  Since I derived them on my own, I can't point people to a very clear explanation.  The goal of this post is to spare people from the pain of working through the tedious calculations.

#Derivation of backprop equations
In this short blog post I will derive the backprop equations for LSTM networks. This blog assumes you understand the forward pass of an LSTM network, as this part is relatively simple.  Please read this [great intro paper](http://arxiv.org/abs/1506.00019) as it contains a very nice intro to LSTM's.  I follow the same notation as this paper so I recommend reading having the tutorial open in a separate browser tab for easy reference while reading this tutorial.

The forward pass of an LSTM node is defined as follows:

$$\begin{eqnarray}
g(t) &=& \phi(W_{gx} x(t) + W_{gh} h(t-1) + b_{g}) \\ 
i(t) &=& \sigma(W_{ix} x(t) + W_{ih} h(t-1) + b_{i}) \\ 
f(t) &=& \sigma(W_{fx} x(t) + W_{fh} h(t-1) + b_{f}) \\ 
o(t) &=& \sigma(W_{ox} x(t) + W_{oh} h(t-1) + b_{o}) \\ 
s(t) &=& g(t) * i(t) + s(t-1) * f(t)  \\ 
h(t) &=& s(t) * o(t) \\ 
\end{eqnarray}$$

Suppose we have a loss $l_i$ that we wish to minimize at every time step $i$ that depends on the hidden layer $h$ and the label $y$ at every time step: 

$$
l_i = f(h(i), y(i)).
$$

Our ultimate goal in this case is to minimize the loss $L$ over an entire sequence of length $n$:

$$
L = \sum_{i=1}^{n} l_i
$$

We now define a variable $L_i$ that represents the cumulative loss from step $i$ onwards:

$$
L_i = \sum_{j=i}^{j=n} l_j 
$$

such that $L_1$ is the loss for the entire sequence.  This new variable allows us to express the following recursion:

$$
L_i = l_i + L_{i+1}
$$

where we take $L_{n+1} = 0$.  Hence, given activation $h(t)$ of an LSTM node at time $t$, we have that:

$$
\frac{dL_i}{dh(t)} = \frac{dl_i}{dh(t)} + \frac{dL_{i+1}}{dh(t)}
$$

This notion is expressed in the interface of the LstmNode class:

{% highlight python %}
def top_diff_is(self, top_diff_h, top_diff_s):
    # notice that top_diff_s is carried along the constant error carousel
    ds = self.state.o * top_diff_h + top_diff_s
    do = self.state.s * top_diff_h
    di = self.state.g * ds
    dg = self.state.i * ds
    df = self.s_prev * ds

    # diffs w.r.t. vector inside sigma / tanh function
    di_input = (1. - self.state.i) * self.state.i * di 
    df_input = (1. - self.state.f) * self.state.f * df 
    do_input = (1. - self.state.o) * self.state.o * do 
    dg_input = (1. - self.state.g ** 2) * dg

    # diffs w.r.t. inputs
    self.param.wi_diff += np.outer(di_input, self.xc)
    self.param.wf_diff += np.outer(df_input, self.xc)
    self.param.wo_diff += np.outer(do_input, self.xc)
    self.param.wg_diff += np.outer(dg_input, self.xc)
    self.param.bi_diff += di_input
    self.param.bf_diff += df_input       
    self.param.bo_diff += do_input
    self.param.bg_diff += dg_input       

    # compute bottom diff
    dxc = np.zeros_like(self.xc)
    dxc += np.dot(self.param.wi.T, di_input)
    dxc += np.dot(self.param.wf.T, df_input)
    dxc += np.dot(self.param.wo.T, do_input)
    dxc += np.dot(self.param.wg.T, dg_input)

    # save bottom diffs
    self.state.bottom_diff_s = ds * self.state.f
    self.state.bottom_diff_x = dxc[:self.param.x_dim]
    self.state.bottom_diff_h = dxc[self.param.x_dim:]
{% endhighlight %}

, where we have

$$
\text{top_diff_h} = \frac{dL{i+1}}{dh(t)} \\ 
\text{top_diff_s} = \frac{dL{i+1}}{ds(t)}
$$

With these considerations in mind, we derive the backprop equations:

$$
\begin{eqnarray}
\frac{dL}{ds_{k}(t)} &=&  \frac{dL}{dh_k(t)} \frac{dh_k(t)}{ds_k(t)} \\ 
&=& \frac{dL}{dh_k(t)} o_k(t)
\end{eqnarray}
$$

from which:

{% highlight python %}
ds = self.state.o * top_diff_h + top_diff_s
do = self.state.s * top_diff_h
di = self.state.g * ds
dg = self.state.i * ds
df = self.s_prev * ds
{% endhighlight %}

where we use:

$$
ds = \frac{dL_{t}}{ds(t)}
$$

and so on.  
